# Hasse graph interpretation of CCNNs

In this section, we scrutinize the properties of our topological learning machines by establishing connections to the pre-existing findings regarding GNNs. We begin our inquiry by elucidating the interpretation of CCs as specialized graphs, known as *Hasse graphs*, followed by characterizing their equivariance properties against the actions of permutations and orientations. We further link our definitions of equivariances to the conventional ones under the Hasse graph representation.

## Hasse graph interpretation of CCNNs

We first demonstrate that every CC can be reduced to a unique and special graph known as the *Hasse graph*. This reduction enables us to analyze and understand various computational and conceptual aspects of CCNNs in terms of graph-based models.

### CCs as Hasse graphs

Definition \@ref(def:maps) implies that a CC is a poset, that is a partially ordered set whose partial order relation is the set inclusion relation. It also implies that two CCs are equivalent if and only if their posets are equivalent^[For related structures (e.g., simplicial/cell complexes), this poset is typically called the *face poset* [@wachs2006poset].]. Definition \@ref(def:hg) introduces the *Hasse graph* [@wachs2006poset; @abramenko2008buildings] of a CC, which is a directed graph associated with a finite poset.

```{definition, hg, name="Hasse graph"}
The *Hasse graph* of a CC $(S, \mathcal{X},\mbox{rk})$ is a directed graph $\mathcal{H}_{\mathcal{X}}= (V (\mathcal{H}_{\mathcal{X}}), E(\mathcal{H}_{\mathcal{X}}) )$ with vertices $V (\mathcal{H}_{\mathcal{X}})=\mathcal{X}$ and edges $E(\mathcal{H}_{\mathcal{X}})=\{ (x,y) : x\subsetneq y, \mbox{rk}(x)=\mbox{rk}(y)-1 \}$.
```

The vertices of the Hasse graph $\mathcal{H}_{\mathcal{X}}$ of a CC $(S, \mathcal{X},\mbox{rk})$ are the cells of $\mathcal{X}$, while the edges of $\mathcal{H}_{\mathcal{X}}$ are determined by the immediate incidence among these cells. Figure \@ref(fig:hasse-diagram) shows an example of the Hasse graph of a CC.

```{r hasse-diagram, echo=FALSE, fig.align="center", fig.cap="Example of the Hasse graph of a CC. (a): CC of a M\"{o}bius strip. (b): Hasse graph of the CC, describing the poset structure between cells. (c): Hasse graph augmented with the edges defined via $A_{0,1}$ and $coA_{2,1}$."}
knitr::include_graphics('figures/poset.png', dpi=NA)
```

The *CC structure class* is the set of CCs determined up to isomorphism, according to Definition \@ref(def:maps). Proposition \@ref(prp:structure) provides sufficient criteria for determining CC structure classes. The proof of Proposition \@ref(prp:structure) relies on the observations that CC structure classes are determined by the underlying Hasse graph representation and that the Hasse graph provides the same information as the incidence matrices $\{B_{k,k+1}\}_{k=0}^{\dim(\mathcal{X})-1}$. Figure \@ref(fig:vis-structure) supports visually the proofs of parts 2 and 3 in Proposition \@ref(prp:structure).

```{proposition, structure, name="Determining a CC structure"}
Let $(S, \mathcal{X},\mbox{rk})$ be a CC. For the CC structure class indicated by $(S, \mathcal{X},\mbox{rk})$, the following sufficient conditions hold:

1. The CC structure class is determined by the incidence matrices $\{B_{k,k+1}\}_{k=0}^{ \dim(\mathcal{X}) -1}$.
2. The CC structure class is determined by the adjacency matrices $\{A_{k,1}\}_{k=0}^{\dim(\mathcal{X})-1}$.
3. The CC structure class is determined by the coadjacency matrices $\{coA_{k,1}\}_{k=1}^{\dim(\mathcal{X})}$.
```

```{proof}
The proof of the three parts of the proposition follows by noting that the structure of a CC is determined completely by its Hasse graph representation. The first part of the proposition follows from the fact that the edges in the Hasse graph are precisely the non-zero entries of matrices $\{B_{k,k+1}\}_{k=0}^{\dim(\mathcal{X}-1)}$. The second part follows by observing that two $(k-1)$ cells $x^{k-1}$ and $y^{k-1}$ are 1-adjacent if and only if there exists a $k$-cell $z^k$ that is incident to $x^{k-1}$ and $y^{k-1}$. The third part is confirmed by noting that two $(k+1)$-cells $x^{k+1}$ and $y^{k+1}$ are 1-coadjacent if and only if there exists a $k$-cell $z^k$ that is incident to $x^{k+1}$ and $y^{k+1}$.
```

```{r vis-structure, echo=FALSE, fig.align="center", fig.cap="Relation between immediate incidence and (co)adjacency on the Hasse graph of a CC. (a): Two $(k-1)$ cells $x^{k-1}$ and $y^{k-1}$ (orange vertices) are 1-adjacent if and only if there exists a $k$-cell $z^k$ (pink vertex) that is incident to $x^{k-1}$ and $y^{k-1}$. (b): Two $(k+1)$ cells $x^{k+1}$ and $y^{k+1}$ (blue vertices) are 1-coadjacent if and only if there exists a $k$-cell $z^k$ (pink vertex) that is incident to $x^{k+1}$ and $y^{k+1}$."}
knitr::include_graphics('figures/prop_structure.png', dpi=NA)
```

### Augmented Hasse graphs

The Hasse graph of a CC is useful because it shows that computations for a higher-order deep learning model can be reduced to computations for a graph-based model. Particularly, a $k$-cochain (signal) being processed on a CC $\mathcal{X}$ can be thought as a signal on the corresponding vertices of the associated Hasse graph $\mathcal{H}_{\mathcal{X}}$. The edges specified by the matrices $B_{k,k+1}$ determine the message-passing structure of a given higher-order model defined on $\mathcal{X}$. However, the message-passing structure determined via the matrices $A_{r,k}$ is not directly supported on the corresponding edges of $\mathcal{H}_{\mathcal{X}}$. Thus, it is sometimes desirable to *augment the Hasse graph* with additional edges other than the ones specified by the poset partial order relation of the CC. Along these lines, Definition \@ref(def:ahg) introduces the notion of augmented Hasse graph.

```{definition, ahg, name="Augmented Hasse graph"}
Let $\mathcal{X}$ be a CC, and let $\mathcal{H}_{\mathcal{X}}$ be its Hasse graph with vertex set $V(\mathcal{H}_{\mathcal{X}})$ and edge set $E(\mathcal{H}_{\mathcal{X}})$. Let $\mathcal{N}=\{\mathcal{N}_1,\ldots,\mathcal{N}_n\}$ be a set of neighborhood functions defined on $\mathcal{X}$. We say that $\mathcal{H}_{\mathcal{X}}$ has an augmented edge $e_{x,y}$ induced by $\mathcal{N}$ if there exist $\mathcal{N}_i \in \mathcal{N}$ such that $x \in \mathcal{N}_i(y)$ or $y \in \mathcal{N}_i(x)$. Denote by $E_{\mathcal{N}}$ the set of all augmented edges induced by  $\mathcal{N}$. The *augmented Hasse graph* of $\mathcal{X}$ induced by $\mathcal{N}$ is defined to be the graph $\mathcal{H}_{\mathcal{X}}(\mathcal{N})= (V(\mathcal{H}_{\mathcal{X}}), E(\mathcal{H}_{\mathcal{X}}) \cup E_{\mathcal{N}})$.
```

It is easier to think of the augmented Hasse graph in Definition \@ref(def:ahg) in terms of the matrices $\mathbf{G}=\{G_1,\ldots,G_n\}$ associated with the neighborhood functions $\mathcal{N}=\{\mathcal{N}_1,\ldots,\mathcal{N}_n\}$. Each augmented edge in $\mathcal{H}_{\mathcal{X}}(\mathcal{N})$ corresponds to a non-zero entry in some $G_i\in \mathbf{G}$. Since $\mathcal{N}$ and $\mathbf{G}$ store equivalent information, we use $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$ to denote the augmented Hasse graph induced by the edges determined by $\mathbf{G}$. For instance, the graph given in Figure \@ref(fig:hasse-diagram)(c) is denoted by $\mathcal{H}_{\mathcal{X}}( A_{0,1},coA_{2,1})$.

### Reducibility of CCNNs to graph-based models

In this section, we show that any CCNN-based computational model can be realized as a message-passing scheme over a subgraph of the augmented Hasse graph of the underlying CC. Every CCNN is determined via a computational tensor diagram, which can be built using the elementary tensor operations, namely push-forward operations, merge nodes and split nodes. Thus, the reducibility of CCNN-based computations to message-passing schemes over graphs can be achieved by proving that these three tensor operations can be executed on an augmented Hasse graph. Proposition \@ref(prp:hasse-pushforward) states that push-forward operations are executable on augmented Hasse graphs.

```{proposition, hasse-pushforward, name="Computation over augmented Hasse graph"}
Let $\mathcal{X}$ be a CC and let  $\mathcal{F}_G \colon \mathcal{C}^i(\mathcal{X})\to \mathcal{C}^j(\mathcal{X})$ be a push-forward operator induced by a cochain map $G\colon\mathcal{C}^i(\mathcal{X})\to \mathcal{C}^j(\mathcal{X})$. Any computation executed via $\mathcal{F}_G$ can be reduced to a corresponding computation over the augmented Hassed graph $\mathcal{H}_{\mathcal{X}}(G)$ of $\mathcal{X}$.
```

```{proof}
Let $\mathcal{X}$ be a CC. Let $\mathcal{H}_{\mathcal{X}}(G)$ be the augmented Hasse graph of $\mathcal{X}$ determined by $G$. The definition of the augmented Hasse graph implies that there is a one-to-one correspondence between the vertices $\mathcal{H}_{\mathcal{X}}(G)$ and the cells in $\mathcal{X}$. Given a cell $x\in \mathcal{X}$, let $x^{\prime}$ be the corresponding vertex in $\mathcal{H}_{\mathcal{X}}(G)$. Let $y$ be a cell in $\mathcal{X}$ with a feature vector $\mathbf{h}_y$ computed via the push-forward operation specified by Equation \@ref(eq:functional). Recall that the vector $\mathbf{h}_y$ is computed by aggregating all vectors $\mathbf{h}_x$ attached to the neighbors $x \in \mathcal{X}^i$ of $y$ with respect to the neighborhood function $\mathcal{N}_{G^T}$. Let $m_{x,y}$ be a computation (message) that is executed between two cells $x$ and $y$ of $\mathcal{X}$ as a part of the computation of push-forward $\mathcal{F}_G$. It follows from the augmented Hasse graph definition that the cells $x$ and $y$ must have a corresponding non-zero entry in matrix $G$. Moreover, this non-zero entry corresponds to an edge in $\mathcal{H}_{\mathcal{X}}(G)$ between $x^{\prime}$ and $y^{\prime}$. Thus, the computation $m_{x,y}$ between the cells $x$ and $y$ of $\mathcal{X}$ can be carried out as the computation (message) $m_{x^{\prime},y^{\prime}}$ between the corresponding vertices $x^{\prime}$ and $y^{\prime}$ of $\mathcal{H}_{\mathcal{X}}(G)$.
```

Similarly, computations on an arbitrary merge node can be characterized in terms of computations on a subgraph of the augmented Hasse graph of the underlying CC. Proposition \@ref(prp:hasse) formalizes this statement.

```{proposition, hasse, name="Reduction of merge node to augmented Hasse graph"}
Any computation executed via a merge node $\mathcal{M}_{\mathbf{G},\mathbf{W}}$ as given in Equation \@ref(eq:sum) can be reduced to a corresponding computation over the augmented Hasse graph $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$ of the underlying CC.
```

```{proof}
Let $\mathcal{X}$ be a CC. Let $\mathbf{G}=\{ G_1,\ldots,G_n\}$ be a sequence of cochain operators defined on $\mathcal{X}$. Let $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$ be the augmented Hasse graph determined by $\mathbf{G}$. By the augmented Hasse graph definition, there is a one-to-one correspondence between the vertices of $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$  and the cells of $\mathcal{X}$. For each cell $x\in \mathcal{X}$, let $x^{\prime}$ be the corresponding vertex in $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$. Let $m_{x,y}$ be a computation (message) that is executed between two cells $x$ and $y$ of $\mathcal{X}$ as part of the evaluation of function $\mathcal{M}_{\mathbf{G},W}$. Hence, the two cells $x$ and $y$ must have a corresponding non-zero entry in a matrix $G_i\in\mathbf{G}$. By the augmented Hasse graph definition, this non-zero entry corresponds to an edge in $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$ between $x^{\prime}$ and $y^{\prime}$. Thus, the computation $m_{x,y}$ between the cells $x$ and $y$ of $\mathcal{X}$ can be carried out as the computation (message) $m_{x^{\prime},y^{\prime}}$ between the corresponding vertices $x^{\prime}$ and $y^{\prime}$ of $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$.
```

Propositions \@ref(prp:hasse-pushforward) and \@ref(prp:hasse) ensure that push-forward and merge node computations can be realized on augmented Hasse graphs. Theorem \@ref(thm:hasse-theorem) generalizes Propositions \@ref(prp:hasse-pushforward) and \@ref(prp:hasse), stating that any computation on tensor diagrams is realizable on augmented Hasse graphs.

```{theorem, hasse-theorem, name="Reduction of tensor diagram to augmented Hasse graph"}
Any computation executed via a tensor diagram $\mbox{CCNN}_{\mathbf{G};\mathbf{W}}$ can be reduced to a corresponding computation on the augmented Hasse graph $\mathcal{H}_{\mathcal{X}}(\mathbf{G})$.
```

```{proof}
The conclusion follows directly from Propositions \@ref(prp:hasse) and \@ref(prp:hasse-pushforward), along with the fact that any tensor diagram can be realized in terms of the three elementary tensor operations.
```

According to Theorem \@ref(thm:hasse-theorem), a tensor diagram and its corresponding augmented Hasse graph encode the same computations in alternative forms. Figure \@ref(fig:hasse-diagram-examples) illustrates that the augmented Hasse graph
provides a computational summary of the associated tensor diagram representation of a CCNN.

```{r hasse-diagram-examples, echo=FALSE, fig.align="center", fig.cap="Tensor diagrams of two CCNNs and their corresponding augmented Hasse graphs. Edge labels are dropped from the tensor diagrams to avoid clutter, as they can be inferred from the corresponding augmented Hasse graphs. (a): A tensor diagram obtained from a higher-order message-passing scheme. (b): A tensor diagram obtained by using the three elementary tensor operations."}
knitr::include_graphics('figures/augmented_hasse_graph_examples.png', dpi=NA)
```
