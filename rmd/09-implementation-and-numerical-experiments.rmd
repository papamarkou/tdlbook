# (PART\*) Part IV: Applications, literature and conclusions {-}

# Implementation and numerical results

The proposed CCNNs can be used to construct different neural network architectures for diverse learning tasks. In this section, we demonstrate the generality and the efficacy of CCNNs by evaluating their predictive performance on shape analysis and graph learning tasks. In our geometric processing experiments, we compare CCNNs against state-of-the-art methods, which are highly engineered and trained towards specific tasks. Furthermore, we conduct our experiments on various data modalities commonly studied in geometric data processing, namely on point clouds and 3D meshes. We also perform experiments on graph data. In our experiments, we tune three main components: the choice of CCNN architecture, the learning rate, and the number of replications in data augmentation. We justify the choice of CCNN architecture for each learning task. We have implemented our pipeline in PyTorch, and ran the experiments on a single GPU NVIDIA GeForce RTX 3060 Ti using a Microsoft Windows back-end.

## Software: TopoNetX, TopoEmbedX, and TopoModelX

All our software development and experimental analysis have been carried out using Python. We have developed three Python packages, which we have also used to run our experiments: [TopoNetX](https://github.com/pyt-team/TopoNetX), [TopoEmbedX](https://github.com/pyt-team/TopoEmbedX) and [TopoModelX](https://github.com/pyt-team/TopoModelX). TopoNetX supports the construction of several topological structures, including cell complex, simplicial complex, and combinatorial complex classes. These classes provide methods for computing boundary operators, Hodge Laplacians and higher-order adjacency operators on cell, simplicial, and combinatorial complexes, respectively. TopoEmbedX supports representation learning of higher-order relations on cell complexes, simplicial complexes, and combinatorial complexes. TopoModelX supports computing deep learning models defined on these topological domains.

In addition to our software package implementations, we have utilized PyTorch [@paszke2017automatic] for training the neural networks reported in this section. Also, we have utilized Scikit-learn [@scikit-learn] to compute the eigenvectors of the 1-Hodge Laplacians. The normal vectors of point clouds have been computed using the Point Cloud Utils package [@point-cloud-utils]. Finally, we have used NetworkX [@hagberg2008exploring] and HyperNetX [@joslyn2021hypernetwork], both in the development of our software packages as well as in our computations.

## Datasets

In our evaluation of CCNNs, we use four datasets: the Human Body, the COSEG, the SHREC11, and a benchmark dataset for graph classification taken from [@bianchi2020mincutpool]. A summary of these datasets follows.

**Human Body segmentation dataset**. The original Human Body segmentation dataset presented in [@atzmon2018point] contains relatively large meshes with a size up to 12,000 vertices. The segmentation labels provided in this dataset are set per-face, and the segmentation accuracy is defined to be the ratio of the correctly classified faces over the total number of faces in the entire dataset. In this work, we use a simplified version of the original Human Body dataset, as provided by [@hanocka2019meshcnn], in which meshes have less than 1,000 nodes and segmentation labels are remapped to edges. We use this simplified version of the Human Body dataset for the shape analysis (i.e., mesh segmentation) task in Section \@ref(mesh-segmentation).

**COSEG segmentation dataset**. The original COSEG dataset [@wang2012active] contains eleven sets of shapes with ground-truth segmentation. In this work, we use a subset of the original COSEG dataset that contains relatively large sets of aliens, vases, and chairs. These three sets consist of 200, 300, and 400 shapes, respectively. We use this custom subset of the COSEG dataset for the shape analysis (i.e., mesh segmentation) task in Section \@ref(mesh-segmentation).

**SHREC11 classification dataset**. SHREC 2011 [@lian2011shape], abbreviated as SHREC11, is a large-scale dataset that contains 600 nonrigid deformed shapes (watertight triangle meshes) from 30 categories, where each category contains an equal number of objects. Examples of these categories include hand, lamp, woman, man, flamingo, and rabbit. The dataset is available as a training and test set consisting of 480 and 120 shapes, respectively. We use the SHREC11 dataset for the shape analysis tasks in Sections \@ref(mesh-and-point-cloud-classification) and \@ref(pooling-with-mapper-on-graphs-and-data-classification).

**Benchmark dataset for graph classification**. This dataset has graphs belonging to three different classes [@bianchi2020mincutpool]. For each graph, the feature vector on each vertex (the 0-cochain) is a one-hot vector of size five, and it stores the relative position of the vertices on the graph. This dataset has easy and hard versions. The easy version has highly connected graphs, while the hard version has sparse graphs. We use this dataset for the graph classification task in Section \@ref(graph-classification).

## Shape analysis: mesh segmentation and classification

The CC structure used for the shape analysis experiments (mesh segmentation and classification) is simply induced by the triangulation of the meshes. Specifically, the 0-, 1-, and 2-cells are the vertices, edges, and faces of the mesh, respectively. The matrices used for the CCNNs are $B_{0,1},~B_{0,2}$, their transpose matrices, and the (co)adjacency matrices $A_{1,1}$, $coA_{1,1}$, and $coA_{2,1}$.

A CCNN takes a vector of cochains as input features. For shape analysis tasks, we consider cochains, whose features are built directly from the vertex coordinates of the underlying mesh. We note that other choices (e.g., spectral-based cochains as in [@mejia2017spectral]) can also be included. Our shape analysis tasks have three input cochains: the vertex, edge and face cochains. Each vertex cochain has two input features: the position and the normal vectors associated with the vertex. Similar to [@hanocka2019meshcnn], each edge cochain consists of five features: the length of the edge, the dihedral angle, two inner angles, and two edge-length ratios for each face. Finally, each input face cochain consists of three input features: the face area, face normal, and the three face angles.

### Mesh segmentation

For the Human Body dataset [@maron2017convolutional], we built a CCNN that produces an edge class. The tensor diagram of the architecture is shown in Figure \@ref(fig:mesh-net)(a). For the COSEG dataset [@wang2012active], we built a CCNN that combines our proposed feature vectors defined on vertices, edges, and faces to learn the final face class. The architecture uses incidence matrices as well as (co)adjacency matrices to construct a signal flow as demonstrated in Figure \@ref(fig:mesh-net)(b). Specifically, the tensor diagram displays three non-squared attention-blocks and three squared attention blocks. The depth of the model is chosen to be two, as indicated in Figure \@ref(fig:mesh-net)(b).

```{r mesh-net, echo=FALSE, fig.align="center", fig.cap="The tensor diagrams of the CCNNs used in our experiments. (a): The CCNNs used in the mesh segmentation tasks. In particular, $\\mbox{CCNN}_{HB}$ and $\\mbox{CCNN}_{COSEG}$ are the architectures used on the Human Body dataset [@atzmon2018point] and on the COSEG dataset [@wang2012active], respectively. (b): The mesh classification CCNN used on the SHREC11 dataset [@lian2011shape]. (c): The graph classification CCNN used on the dataset provided in [@bianchi2020mincutpool]. (d): The mesh/point cloud classification CCNNs used in conjunction with the MOG algorithm on the SHREC11 dataset."}
knitr::include_graphics('figures/experiment.png', dpi=NA)
```

Note that the architectures chosen for the COSEG and for the Human Body datasets have the same number and types of building blocks; compare Figures \@ref(fig:mesh-net)(a) and (b). We use a random 85%-15% train-test split. For both of these architectures, a softmax activation is applied to the output tensor. All our segmentation models are trained for 600 epochs using a learning rate of 0.0001 and the standard cross-entropy loss. These results are consistent across Human Body and Shape COSEG datasets.

We test the proposed CCNNs on mesh segmentation using the Human Body [@maron2017convolutional] and the Shape COSEG (vase, chair, and alien) [@wang2012active] datasets. For each mesh in these datasets, the utilized CC structure is the one induced by the triangulation of the meshes, although other variations in the CC structure yield comparable results. Further, three $k$-cochains are constructed for $0\leq k \leq 2$ and are utilized in CCNN training. As shown in Table \@ref(tab:shape-xp), CCNNs outperform three neural networks tailored to mesh analysis (HodgeNet [@smirnov2021hodgenet], PD-MeshNet [@milano2020primal] and MeshCCN [@hanocka2019meshcnn]) on two out of four datasets, and are among the best two neural networks on all four datasets.

```{r shape-xp, echo=FALSE}
methods <- c('HodgeNet', 'PD-MeshNet', 'MeshCNN', 'CCNN')
hb <- c('85.03', '85.61', '85.39', '87.30')
cosegv <- c('90.30', '95.36', '92.36', '93.40')
cosegc <- c('95.68', '97.23', '92.99', '98.30')
cosega <- c('96.03', '98.18', '96.26', '93.70')
domains <- data.frame(methods, hb, cosegv, cosegc, cosega)
colnames(domains) <- c('Method', 'Human Body', 'COSEG vase', 'COSEG chair', 'COSEG alien')
knitr::kable(domains, align=c('l', 'c', 'c', 'c', 'c'), booktabs=TRUE, caption="Predictive accuracy on test sets related to shape analysis, namely on Human Body and COSEG (vase, chair, alien) datasets. The results reported here are based on the $\\mbox{CCNN}_{COSEG}$ and $\\mbox{CCNN}_{HB}$ architectures. In particular, the result for $\\mbox{CCNN}_{HB}$ is reported in the first column, whereas the results for $\\mbox{CCNN}_{COSEG}$ are reported in the second, third and forth columns.")
```

**Architecture of $\mbox{CCNN}_{COSEG}$ and  $\mbox{CCNN}_{HB}$**. In $\mbox{CCNN}_{COSEG}$, as shown in Figure \@ref(fig:mesh-net)(a), we choose a CCNN pooling architecture as given in Definition \@ref(def:general-pooling-hoan), which pushes signals from vertices, edges and faces, and aggregates their information towards the final face prediction class. We choose $\mbox{CCNN}_{HB}$ similarly, except that the predicted signal is an edge class. The reason for this choice is that the Human Body dataset [@atzmon2018point] encodes the segmentation information on edges.

### Mesh and point cloud classification

We evaluate our method on mesh classification using the SHREC11 dataset [@lian2011shape] based on the same cochains and CC structure used in the segmentation experiment of Section \@ref(mesh-segmentation). The CCNN architecture for our mesh classification task, denoted by $\mbox{CCNN}_{SHREC}$, is demonstrated in Figure \@ref(fig:mesh-net)(b). The final layer of $\mbox{CCNN}_{SHREC}$, depicted as a grey node in Figure \@ref(fig:mesh-net)(b), is a simple pooling operation that sums all embeddings of the CC after mapping them to the same Euclidean space. The $\mbox{CCNN}_{SHREC}$ is trained for 40 epochs with both tanh and identity activation functions using a learning rate of 0.005 and the standard cross-entropy loss. We use anisotropic scaling and random rotations for data augmentation. Each mesh is augmented 30 times, is centered around the vertex center of the mass, and is rescaled to fit inside the unit cube.

The $\mbox{CCNN}_{SHREC}$ with identity activations and $\tanh$ activations achieve predictive accuracies of 96.67% and 99.17%, respectively. Table \@ref(tab:shrec) shows that CCNNs outperform two neural networks tailored to mesh analysis (HodgeNet and MeshCCN), being the second best model behind PD-MeshNet in mesh and point cloud classification. It is worth mentioning that the mesh classification CCNN requires a significantly lower number of epochs to train (40 epochs) as compared to the mesh segmentation CCNNs (600 epochs).

```{r shrec, echo=FALSE}
methods <- c('HodgeNet', 'PD-MeshNet', 'MeshCNN', 'CCNN')
mesh <- c('99.10', '99.70', '98.60', '99.17')
pointcloud <- c('94.70', '99.10', '91.00', '95.20')
domains <- data.frame(methods, mesh, pointcloud)
colnames(domains) <- c('Method', 'Mesh', 'Point cloud')
knitr::kable(domains, align=c('l', 'c', 'c'), booktabs=TRUE, caption="Predictive accuracy on the SHREC11 test dataset. The left and right column report the mesh and point cloud classification results, respectively. The CCNN for mesh classification is $\\mbox{CCNN}_{SHREC}$, while the CCNN for point cloud classification is $\\mbox{CCNN}_{MOG2}$.")
```

**Architecture of $\mbox{CCNN}_{SHREC}$**. The $\mbox{CCNN}_{SHREC}$ has two layers and is chosen as a pooling CCNN in the sense of Definition \@ref(def:general-pooling-hoan), similar to $\mbox{CCNN}_{COSEG}$ and $\mbox{CCNN}_{HB}$. The main difference is that the final layer of $\mbox{CCNN}_{SHREC}$, represented by the grey point in Figure \@ref(fig:mesh-net)(b), is a global pooling function that sums all embeddings of all dimensions (zero, one and two) of the underlying CC after mapping them to the same Euclidean space.

### Graph classification

For the graph classification task, we use the graph classification benchmark provided in [@bianchi2020mincutpool]; the dataset consists of graphs with three different labels. For each graph, the feature vector on each vertex (the 0-cochain) is a one-hot vector of size five, and it stores the relative position of the vertex on the graph. To construct the CC structure, we use the 2-clique complex of the input graph. We then proceed to build the CCNN for graph classification, denoted by $\mbox{CCNN}_{Graph}$, which is visualized in Figure \@ref(fig:mesh-net)(c). The matrices used for the construction of $\mbox{CCNN}_{Graph}$ are $B_{0,1},~B_{1,2},~B_{0,2}$, their transpose matrices, and the (co)adjacency matrices $A_{0,1},A_{1,1},~coA_{2,1}$. The cochains of $\mbox{CCNN}_{Graph}$ are constructed as follows. For each graph in the dataset, we set the 0-cochain to be the one-hot vector of size 5 provided by the dataset. This one-hot vector stores the relative position of the vertex on the graph. We also construct the 1-cochain and 2-cochain on the 2-clique complex of the graph by considering the coordinate-wise max value of the one-hot vectors attached to the vertices of each cell. The input to $\mbox{CCNN}_{graoh}$ consists of the 0-cochain provided as a part of the dataset as well as the constructed 1 and 2-cochains. The grey node in Figure \@ref(fig:mesh-net)(c) indicates a simple mean pooling operation. We train this network with a learning rate of 0.005 and no data augmentation.

Table \@ref(tab:wrap-tab) reports the results on the *easy* and the *hard* versions of the datasets^[The difficulty in these datasets is controlled by the compactness degree of the graph clusters; clusters in the 'easy' data have more in-between cluster connections, while clusters in the `hard' data are more isolated [@bianchi2020mincutpool].], and compares them to six state-of-the-art GNNs. As shown in Table \@ref(tab:wrap-tab), CCNNs outperform all six GNNs on the hard dataset, and five of the GNNs on the easy dataset. The proposed CCNN outperforms MinCutPool on the hard dataset, while it attains comparable performance to MinCutPool on the easy dataset.

```{r wrap-tab, echo=FALSE}
dsets <- c('Easy', 'Hard')
graclus <- c('97.81', '69.08')
ndp <- c('97.93', '72.67')
diffpool <- c('98.64', '69.98')
topk <- c('82.47', '42.80')
sagpool <- c('84.23', '37.71')
mincutpool <- c('99.02', '73.80')
ccnn <- c('98.90', '75.59')
domains <- data.frame(
  dsets, graclus, ndp, diffpool, topk, sagpool, mincutpool, ccnn
)
colnames(domains) <- c(
  'Dataset',
  'Graclus',
  'NDP',
  'DiffPool',
  'Top-K',
  'SAGPool',
  'MinCutPool',
  'CCNN'
)
knitr::kable(domains, align=c('l', 'c', 'c', 'c', 'c'), booktabs=TRUE, caption="Predictive accuracy on the test set of [@bianchi2020mincutpool] related to graph classification. All results are reported using the $\\mbox{CCNN}_{Graph}$ architecture.")
```

**Architecture of  $\mbox{CCNN}_{Graph}$**. In the $\mbox{CCNN}_{Graph}$ displayed in Figure \@ref(fig:mesh-net)(c) we choose a CCNN pooling architecture as given in Definition \@ref(def:general-pooling-hoan) that pushes signals from vertices, edges and faces, and aggregate their information towards the higher-order cells before making making the final prediction. For the dataset of [@bianchi2020mincutpool], we experiment with two architectures; the first one is identical to the $\mbox{CCNN}_{SHREC}$ shown in Figure \@ref(fig:mesh-net)(b), and the second one is the $\mbox{CCNN}_{Graph}$ shown in Figure \@ref(fig:mesh-net)(c). We report the results for $\mbox{CCNN}_{Graph}$, as it provides superior performance. Note that when this neural network is conducted on an underlying simplicial complex, the neighborhood matrices $B_{0,1}$ and $B_{1,3}$ are typically not considered, hence the CC-structure equipped with these additional incidence matrices improves the generalization performance of the $\mbox{CCNN}_{Graph}$.

## Pooling with mapper on graphs and data classification

### Mesh classification: CC-pooling with input vertex and edge features

### Mesh classification: CC-pooling with input vertex features only

### Point cloud classification: CC-pooling with input vertex features only

## Ablation studies

In this section, we perform two ablation studies. The first ablation study reveals that pooling strategies in CCNNs have a crucial effect on predictive performance. The second ablation study demonstrates that CCNNs have better predictive capacity than GNNs; the advantage of CCNNs arises from their topological pooling operations and from their ability to learn from topological features.

**Pooling strategies in CCNNs**. To evaluate the impact of the choice of pooling strategy on predictive performance, we experiment with two pooling strategies using the SHREC11 classification dataset. The first pooling strategy is the MOG algorithm described in Section \@ref(pooling-with-mapper-on-graphs-and-data-classification); the results of this pooling strategy based on $\mbox{CCNN}_{MOG2}$ are discussed in Section \@ref(mesh-classification-cc-pooling-with-input-vertex-features-only) (97.1%). The second pooling strategy is briefly described as follows. For each mesh, we consider the 2-dimensional CC obtained by considering each 1-hop neighborhood to be the 1-cells in the CC and each 2-hop neighborhood to be the 2-cells in the CC. We train $\mbox{CCNN}_{MOG2}$, and obtain an accuracy of 89.2%, which is lower than 97.1%. These experiments suggest that the choice of pooling strategy has a crucial effect on predictive performance.

**Comparing CCNNs to GNNs in terms of predictive performance**. Observe that $\mbox{CCNN}_{SHREC}$ has topological features of dimension one and two as inputs. On the other hand, $\mbox{CCNN}_{MOG2}$ has only vertex features as input, but it learns the higher-order cell latent features by using the push-forward operation that pushes the signal from 0-cells to the 2-cells obtained from the MOG algorithm. In both cases, using a higher-order structure is essential for improving predictive performance, even though two different strategies towards exploiting the higher-order structures are utilized. To support our claim, we run an experiment in which we replace the pooling layer in $\mbox{CCNN}_{MOG2}$ by the cochain operator induced by $A_{0,1}$, effectively rendering the neural network as a GNN. In this setting, using the same setup as in experiment \@ref(mesh-classification-cc-pooling-with-input-vertex-features-only), we obtain an accuracy of 84.56%. This experiment reveals the performance advantages of employing higher-order structures, either by utilizing the input topological features supported on higher-order cells or via pooling strategies that augment higher-order cells.
