# (PART\*) Part IV: Applications, literature and conclusions {-}

# Implementation and numerical results

The proposed CCNNs can be used to construct different neural network architectures for diverse learning tasks. In this section, we demonstrate the generality and the efficacy of CCNNs by evaluating their predictive performance on shape analysis and graph learning tasks. In our geometric processing experiments, we compare CCNNs against state-of-the-art methods, which are highly engineered and trained towards specific tasks. Furthermore, we conduct our experiments on various data modalities commonly studied in geometric data processing, namely on point clouds and 3D meshes. We also perform experiments on graph data. In our experiments, we tune three main components: the choice of CCNN architecture, the learning rate, and the number of replications in data augmentation. We justify the choice of CCNN architecture for each learning task. We have implemented our pipeline in PyTorch, and ran the experiments on a single GPU NVIDIA GeForce RTX 3060 Ti using a Microsoft Windows back-end.

## Software: TopoNetX, TopoEmbedX, and TopoModelX

All our software development and experimental analysis have been carried out using Python. We have developed three Python packages, which we have also used to run our experiments: [TopoNetX](https://github.com/pyt-team/TopoNetX), [TopoEmbedX](https://github.com/pyt-team/TopoEmbedX) and [TopoModelX](https://github.com/pyt-team/TopoModelX). TopoNetX supports the construction of several topological structures, including cell complex, simplicial complex, and combinatorial complex classes. These classes provide methods for computing boundary operators, Hodge Laplacians and higher-order adjacency operators on cell, simplicial, and combinatorial complexes, respectively. TopoEmbedX supports representation learning of higher-order relations on cell complexes, simplicial complexes, and combinatorial complexes. TopoModelX supports computing deep learning models defined on these topological domains.

In addition to our software package implementations, we have utilized PyTorch [@paszke2017automatic] for training the neural networks reported in this section. Also, we have utilized Scikit-learn [@scikit-learn] to compute the eigenvectors of the 1-Hodge Laplacians. The normal vectors of point clouds have been computed using the Point Cloud Utils package [@point-cloud-utils]. Finally, we have used NetworkX [@hagberg2008exploring] and HyperNetX [@joslyn2021hypernetwork], both in the development of our software packages as well as in our computations.

## Datasets

In our evaluation of CCNNs, we use four datasets: the Human Body, the COSEG, the SHREC11, and a benchmark dataset for graph classification taken from [@bianchi2020mincutpool]. A summary of these datasets follows.

**Human Body segmentation dataset**. The original Human Body segmentation dataset presented in [@atzmon2018point] contains relatively large meshes with a size up to 12,000 vertices. The segmentation labels provided in this dataset are set per-face, and the segmentation accuracy is defined to be the ratio of the correctly classified faces over the total number of faces in the entire dataset. In this work, we use a simplified version of the original Human Body dataset, as provided by [@hanocka2019meshcnn], in which meshes have less than 1,000 nodes and segmentation labels are remapped to edges. We use this simplified version of the Human Body dataset for the shape analysis (i.e., mesh segmentation) task in Section \@ref(mesh-segmentation).

**COSEG segmentation dataset**. The original COSEG dataset [@wang2012active] contains eleven sets of shapes with ground-truth segmentation. In this work, we use a subset of the original COSEG dataset that contains relatively large sets of aliens, vases, and chairs. These three sets consist of 200, 300, and 400 shapes, respectively. We use this custom subset of the COSEG dataset for the shape analysis (i.e., mesh segmentation) task in Section \@ref(mesh-segmentation).

**SHREC11 classification dataset**. SHREC 2011 [@lian2011shape], abbreviated as SHREC11, is a large-scale dataset that contains 600 nonrigid deformed shapes (watertight triangle meshes) from 30 categories, where each category contains an equal number of objects. Examples of these categories include hand, lamp, woman, man, flamingo, and rabbit. The dataset is available as a training and test set consisting of 480 and 120 shapes, respectively. We use the SHREC11 dataset for the shape analysis tasks in Sections \@ref(mesh-and-point-cloud-classification) and \@ref(pooling-with-mapper-on-graphs-and-data-classification).

**Benchmark dataset for graph classification**. This dataset has graphs belonging to three different classes [@bianchi2020mincutpool]. For each graph, the feature vector on each vertex (the $0$-cochain) is a one-hot vector of size five, and it stores the relative position of the vertices on the graph. This dataset has easy and hard versions. The easy version has highly connected graphs, while the hard version has sparse graphs. We use this dataset for the graph classification task in Section \@ref(graph-classification).

## Shape analysis: mesh segmentation and classification

The CC structure used for the shape analysis experiments (mesh segmentation and classification) is simply induced by the triangulation of the meshes. Specifically, the $0$-, $1$-, and $2$-cells are the vertices, edges, and faces of the mesh, respectively. The matrices used for the CCNNs are $B_{0,1},~B_{0,2}$, their transpose matrices, and the (co)adjacency matrices $A_{1,1}$, $coA_{1,1}$, and $coA_{2,1}$.

A CCNN takes a vector of cochains as input features. For shape analysis tasks, we consider cochains, whose features are built directly from the vertex coordinates of the underlying mesh. We note that other choices (e.g., spectral-based cochains as in [@mejia2017spectral]) can also be included. Our shape analysis tasks have three input cochains: the vertex, edge and face cochains. Each vertex cochain has two input features: the position and the normal vectors associated with the vertex. Similar to [@hanocka2019meshcnn], each edge cochain consists of five features: the length of the edge, the dihedral angle, two inner angles, and two edge-length ratios for each face. Finally, each input face cochain consists of three input features: the face area, face normal, and the three face angles.

### Mesh segmentation

### Mesh and point cloud classification

### Graph classification

## Pooling with mapper on graphs and data classification

### Mesh classification: CC-pooling with input vertex and edge features

### Mesh classification: CC-pooling with input vertex features only

### Point cloud classification: CC-pooling with input vertex features only

## Ablation studies
