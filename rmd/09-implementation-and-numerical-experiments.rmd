# (PART\*) Part IV: Applications, literature and conclusions {-}

# Implementation and numerical results

The proposed CCNNs can be used to construct different neural network architectures for diverse learning tasks. In this section, we demonstrate the generality and the efficacy of CCNNs by evaluating their predictive performance on shape analysis and graph learning tasks. In our geometric processing experiments, we compare CCNNs against state-of-the-art methods, which are highly engineered and trained towards specific tasks. Furthermore, we conduct our experiments on various data modalities commonly studied in geometric data processing, namely on point clouds and 3D meshes. We also perform experiments on graph data. In our experiments, we tune three main components: the choice of CCNN architecture, the learning rate, and the number of replications in data augmentation. We justify the choice of CCNN architecture for each learning task. We have implemented our pipeline in PyTorch, and ran the experiments on a single GPU NVIDIA GeForce RTX 3060 Ti using a Microsoft Windows back-end.

## Software: TopoNetX, TopoEmbedX, and TopoModelX

All our software development and experimental analysis have been carried out using Python. We have developed three Python packages, which we have also used to run our experiments: [TopoNetX](https://github.com/pyt-team/TopoNetX), [TopoEmbedX](https://github.com/pyt-team/TopoEmbedX) and [TopoModelX](https://github.com/pyt-team/TopoModelX). TopoNetX supports the construction of several topological structures, including cell complex, simplicial complex, and combinatorial complex classes. These classes provide methods for computing boundary operators, Hodge Laplacians and higher-order adjacency operators on cell, simplicial, and combinatorial complexes, respectively. TopoEmbedX supports representation learning of higher-order relations on cell complexes, simplicial complexes, and combinatorial complexes. TopoModelX supports computing deep learning models defined on these topological domains.

In addition to our software package implementations, we have utilized PyTorch [@paszke2017automatic] for training the neural networks reported in this section. Also, we have utilized Scikit-learn [@scikit-learn] to compute the eigenvectors of the 1-Hodge Laplacians. The normal vectors of point clouds have been computed using the Point Cloud Utils package [@point-cloud-utils]. Finally, we have used NetworkX [@hagberg2008exploring] and HyperNetX [@joslyn2021hypernetwork], both in the development of our software packages as well as in our computations.
