# (PART\*) Part IV: Applications, literature and conclusions {-}

# Implementation and numerical results

The proposed CCNNs can be used to construct different neural network architectures for diverse learning tasks. In this section, we demonstrate the generality and the efficacy of CCNNs by evaluating their predictive performance on shape analysis and graph learning tasks. In our geometric processing experiments, we compare CCNNs against state-of-the-art methods, which are highly engineered and trained towards specific tasks. Furthermore, we conduct our experiments on various data modalities commonly studied in geometric data processing, namely on point clouds and 3D meshes. We also perform experiments on graph data. In our experiments, we tune three main components: the choice of CCNN architecture, the learning rate, and the number of replications in data augmentation. We justify the choice of CCNN architecture for each learning task. We have implemented our pipeline in PyTorch, and ran the experiments on a single GPU NVIDIA GeForce RTX 3060 Ti using a Microsoft Windows back-end.

## Software: TopoNetX, TopoEmbedX, and TopoModelX

All our software development and experimental analysis have been carried out using Python. We have developed three Python packages, which we have also used to run our experiments: [TopoNetX](https://github.com/pyt-team/TopoNetX), [TopoEmbedX](https://github.com/pyt-team/TopoEmbedX) and [TopoModelX](https://github.com/pyt-team/TopoModelX). TopoNetX supports the construction of several topological structures, including cell complex, simplicial complex, and combinatorial complex classes. These classes provide methods for computing boundary operators, Hodge Laplacians and higher-order adjacency operators on cell, simplicial, and combinatorial complexes, respectively. TopoEmbedX supports representation learning of higher-order relations on cell complexes, simplicial complexes, and combinatorial complexes. TopoModelX supports computing deep learning models defined on these topological domains.

In addition to our software package implementations, we have utilized PyTorch [@paszke2017automatic] for training the neural networks reported in this section. Also, we have utilized Scikit-learn [@scikit-learn] to compute the eigenvectors of the 1-Hodge Laplacians. The normal vectors of point clouds have been computed using the Point Cloud Utils package [@point-cloud-utils]. Finally, we have used NetworkX [@hagberg2008exploring] and HyperNetX [@joslyn2021hypernetwork], both in the development of our software packages as well as in our computations.

## Datasets

In our evaluation of CCNNs, we use four datasets: the Human Body, the COSEG, the SHREC11, and a benchmark dataset for graph classification taken from [@bianchi2020mincutpool]. A summary of these datasets follows.

**Human Body segmentation dataset**. The original Human Body segmentation dataset presented in [@atzmon2018point] contains relatively large meshes with a size up to 12,000 vertices. The segmentation labels provided in this dataset are set per-face, and the segmentation accuracy is defined to be the ratio of the correctly classified faces over the total number of faces in the entire dataset. In this work, we use a simplified version of the original Human Body dataset, as provided by [@hanocka2019meshcnn], in which meshes have less than 1,000 nodes and segmentation labels are remapped to edges. We use this simplified version of the Human Body dataset for the shape analysis (i.e., mesh segmentation) task in Section \@ref(mesh-segmentation).

**COSEG segmentation dataset**. The original COSEG dataset [@wang2012active] contains eleven sets of shapes with ground-truth segmentation. In this work, we use a subset of the original COSEG dataset that contains relatively large sets of aliens, vases, and chairs. These three sets consist of 200, 300, and 400 shapes, respectively. We use this custom subset of the COSEG dataset for the shape analysis (i.e., mesh segmentation) task in Section \@ref(mesh-segmentation).

**SHREC11 classification dataset**. SHREC 2011 [@lian2011shape], abbreviated as SHREC11, is a large-scale dataset that contains 600 nonrigid deformed shapes (watertight triangle meshes) from 30 categories, where each category contains an equal number of objects. Examples of these categories include hand, lamp, woman, man, flamingo, and rabbit. The dataset is available as a training and test set consisting of 480 and 120 shapes, respectively. We use the SHREC11 dataset for the shape analysis tasks in Sections \@ref(mesh-and-point-cloud-classification) and \@ref(pooling-with-mapper-on-graphs-and-data-classification).

**Benchmark dataset for graph classification**. This dataset has graphs belonging to three different classes [@bianchi2020mincutpool]. For each graph, the feature vector on each vertex (the $0$-cochain) is a one-hot vector of size five, and it stores the relative position of the vertices on the graph. This dataset has easy and hard versions. The easy version has highly connected graphs, while the hard version has sparse graphs. We use this dataset for the graph classification task in Section \@ref(graph-classification).

## Shape analysis: mesh segmentation and classification

The CC structure used for the shape analysis experiments (mesh segmentation and classification) is simply induced by the triangulation of the meshes. Specifically, the $0$-, $1$-, and $2$-cells are the vertices, edges, and faces of the mesh, respectively. The matrices used for the CCNNs are $B_{0,1},~B_{0,2}$, their transpose matrices, and the (co)adjacency matrices $A_{1,1}$, $coA_{1,1}$, and $coA_{2,1}$.

A CCNN takes a vector of cochains as input features. For shape analysis tasks, we consider cochains, whose features are built directly from the vertex coordinates of the underlying mesh. We note that other choices (e.g., spectral-based cochains as in [@mejia2017spectral]) can also be included. Our shape analysis tasks have three input cochains: the vertex, edge and face cochains. Each vertex cochain has two input features: the position and the normal vectors associated with the vertex. Similar to [@hanocka2019meshcnn], each edge cochain consists of five features: the length of the edge, the dihedral angle, two inner angles, and two edge-length ratios for each face. Finally, each input face cochain consists of three input features: the face area, face normal, and the three face angles.

### Mesh segmentation

For the Human Body dataset [@maron2017convolutional], we built a CCNN that produces an edge class. The tensor diagram of the architecture is shown in Figure \@ref(fig:mesh-net)(a). For the COSEG dataset [@wang2012active], we built a CCNN that combines our proposed feature vectors defined on vertices, edges, and faces to learn the final face class. The architecture uses incidence matrices as well as (co)adjacency matrices to construct a signal flow as demonstrated in Figure \@ref(fig:mesh-net)(b). Specifically, the tensor diagram displays three non-squared attention-blocks and three squared attention blocks. The depth of the model is chosen to be two, as indicated in Figure \@ref(fig:mesh-net)(b).

```{r mesh-net, echo=FALSE, fig.align="center", fig.cap="The tensor diagrams of the CCNNs used in our experiments. (a): The CCNNs used in the mesh segmentation tasks. In particular, $\\mbox{CCNN}_{HB}$ and $\\mbox{CCNN}_{COSEG}$ are the architectures used on the Human Body dataset [@atzmon2018point] and on the COSEG dataset [@wang2012active], respectively. (b): The mesh classification CCNN used on the SHREC11 dataset [@lian2011shape]. (c): The graph classification CCNN used on the dataset provided in [@bianchi2020mincutpool]. (d): The mesh/point cloud classification CCNNs used in conjunction with the MOG algorithm on the SHREC11 dataset."}
knitr::include_graphics('figures/experiment.png', dpi=NA)
```

Note that the architectures chosen for the COSEG and for the Human Body datasets have the same number and types of building blocks; compare Figures \@ref(fig:mesh-net)(a) and (b). We use a random $85\%-15\%$ train-test split. For both of these architectures, a softmax activation is applied to the output tensor. All our segmentation models are trained for $600$ epochs using a learning rate of $0.0001$ and the standard cross-entropy loss. These results are consistent across Human Body and Shape COSEG datasets.

We test the proposed CCNNs on mesh segmentation using the Human Body [@maron2017convolutional] and the Shape COSEG (vase, chair, and alien) [@wang2012active] datasets. For each mesh in these datasets, the utilized CC structure is the one induced by the triangulation of the meshes, although other variations in the CC structure yield comparable results. Further, three $k$-cochains are constructed for $0\leq k \leq 2$ and are utilized in CCNN training. As shown in Table \@ref(tab:shape-xp), CCNNs outperform three neural networks tailored to mesh analysis (HodgeNet [@smirnov2021hodgenet], PD-MeshNet [@milano2020primal] and MeshCCN [@hanocka2019meshcnn]) on two out of four datasets, and are among the best two neural networks on all four datasets.

```{r shape-xp, echo=FALSE}
methods <- c('HodgeNet', 'PD-MeshNet', 'MeshCNN', 'CCNN')
hb <- c('85.03', '85.61', '85.39', '87.30')
cosegv <- c('90.30', '95.36', '92.36', '93.40')
cosegc <- c('95.68', '97.23', '92.99', '98.30')
cosega <- c('96.03', '98.18', '96.26', '93.70')
domains <- data.frame(methods, hb, cosegv, cosegc, cosega)
colnames(domains) <- c('Method', 'Human Body', 'COSEG vase', 'COSEG chair', 'COSEG alien')
knitr::kable(domains, align=c('l', 'c', 'c', 'c', 'c'), booktabs=TRUE, caption="Predictive accuracy on test sets related to shape analysis, namely on Human Body and COSEG (vase, chair, alien) datasets. Red and blue colors indicate best and second best results, respectively. The results reported here are based on the $\\mbox{CCNN}_{COSEG}$ and $\\mbox{CCNN}_{HB}$ architectures. In particular, the result for $\\mbox{CCNN}_{HB}$ is reported in the first column, whereas the results for $\\mbox{CCNN}_{COSEG}$ are reported in the second, third and forth columns.")
```

**Architecture of $\mbox{CCNN}_{COSEG}$ and  $\mbox{CCNN}_{HB}$**. In $\mbox{CCNN}_{COSEG}$, as shown in Figure \@ref(fig:mesh-net)(a), we choose a CCNN pooling architecture as given in Definition \@ref(def:general-pooling-hoan), which pushes signals from vertices, edges and faces, and aggregates their information towards the final face prediction class. We choose $\mbox{CCNN}_{HB}$ similarly, except that the predicted signal is an edge class. The reason for this choice is that the Human Body dataset [@atzmon2018point] encodes the segmentation information on edges.

### Mesh and point cloud classification

### Graph classification

## Pooling with mapper on graphs and data classification

### Mesh classification: CC-pooling with input vertex and edge features

### Mesh classification: CC-pooling with input vertex features only

### Point cloud classification: CC-pooling with input vertex features only

## Ablation studies
